{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8-nrMmi8XcuJ"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# global params\n",
        "# trained =  True # loads models with random weight and not pretrained weights\n",
        "case = 'normalized'\n",
        "train_models = True\n",
        "epochs = 10 \n",
        "\n",
        "# num_data"
      ],
      "metadata": {
        "id": "DXjqClFRu9ug"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "Ef55AMmfXcuL"
      },
      "outputs": [],
      "source": [
        "from __future__ import print_function, division\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.backends.cudnn as cudnn\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy\n",
        "import torch.nn.functional as F\n",
        "\n",
        "cudnn.benchmark = True\n",
        "plt.ion()   # interactive mode\n",
        "\n",
        "\n",
        "use_cuda=True\n",
        "device = torch.device(\"cuda\" if (use_cuda and torch.cuda.is_available()) else \"cpu\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST Experiment **I**"
      ],
      "metadata": {
        "id": "O9bsHx_rXtGE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet Model definition\n",
        "class NetTest(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetTest, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))        \n",
        "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))    \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))    \n",
        "\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))        \n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "\n",
        "# LeNet Model definition\n",
        "class NetTest2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetTest2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=2)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=2)\n",
        "        self.conv3 = nn.Conv2d(20, 10, kernel_size=2)\n",
        "        # self.conv3_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(40, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))   \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))        \n",
        "        x = F.relu(F.max_pool2d(self.conv3(x), 2))    \n",
        "\n",
        "        x = x.view(-1, 40)\n",
        "        x = F.relu(self.fc1(x))        \n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "\n",
        "\n",
        "# LeNet Model definition\n",
        "class NetTest3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NetTest3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 30, kernel_size=3)\n",
        "        self.conv2 = nn.Conv2d(30, 20, kernel_size=3)\n",
        "\n",
        "        self.fc1 = nn.Linear(500, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))   \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))        \n",
        "\n",
        "        x = x.view(-1, 500)\n",
        "        x = F.relu(self.fc1(x))        \n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "\n",
        "\n",
        "models = [NetTest().to(device), NetTest2().to(device), NetTest3().to(device)]  # training with slope 1 for now\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=100, shuffle=True)\n",
        "\n",
        "# # MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=100, shuffle=False)\n",
        "\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = train_loader\n",
        "dataloaders['val'] = test_loader\n",
        "\n",
        "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "# # Define what device we are using\n",
        "# print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "\n",
        "num_classes = 10\n",
        "\n"
      ],
      "metadata": {
        "id": "ZnVzyjxP6Sbs"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchsummary import summary\n",
        "summary(models[0], (1, 28, 28))\n",
        "# summary(models[1], (1, 28, 28))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mq1oXkjx_uRW",
        "outputId": "cee866e9-afe7-4a91-80da-2045d99dfa9b"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 10, 24, 24]             260\n",
            "            Conv2d-2             [-1, 20, 8, 8]           5,020\n",
            "            Linear-3                   [-1, 50]          16,050\n",
            "            Linear-4                   [-1, 10]             510\n",
            "================================================================\n",
            "Total params: 21,840\n",
            "Trainable params: 21,840\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.05\n",
            "Params size (MB): 0.08\n",
            "Estimated Total Size (MB): 0.14\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MNIST Experiment **II**"
      ],
      "metadata": {
        "id": "53vS5wrEX4us"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# LeNet Model definition\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(F.max_pool2d(self.conv1(x), 2))        \n",
        "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))    \n",
        "        x = F.relu(F.max_pool2d(self.conv2(x), 2))    \n",
        "\n",
        "        x = x.view(-1, 320)\n",
        "        x = F.relu(self.fc1(x))        \n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "\n",
        "# LeNet Model definition\n",
        "class Net2(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net2, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.max_pool2d(self.conv1(x), 2)\n",
        "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))    \n",
        "        x = F.max_pool2d(self.conv2(x), 2)    \n",
        "\n",
        "        x = x.view(-1, 320)\n",
        "        x = self.fc1(x)        \n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "# LeNet Model definition\n",
        "class Net3(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net3, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
        "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
        "        # self.conv2_drop = nn.Dropout2d()\n",
        "        self.fc1 = nn.Linear(320, 50)\n",
        "        self.fc2 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.tanh(F.max_pool2d(self.conv1(x), 2))        \n",
        "        # x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))    \n",
        "        x = torch.tanh(F.max_pool2d(self.conv2(x), 2))    \n",
        "\n",
        "        x = x.view(-1, 320)\n",
        "        x = torch.tanh(self.fc1(x))        \n",
        "        # x = F.dropout(x, training=self.training)\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x #F.log_softmax(x, dim=1)  ### SUPER IMPORTANT ***************************** works with nll loss loss now\n",
        "#         return x  ### SUPER IMPORTANT ***************************** works with cross entropy loss loss now\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "models = [Net().to(device), Net2().to(device), Net3().to(device)]  # training with slope 1 for now\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=100, shuffle=True)\n",
        "\n",
        "# # MNIST Test dataset and dataloader declaration\n",
        "test_loader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([\n",
        "            transforms.ToTensor(),\n",
        "            ])), \n",
        "        batch_size=100, shuffle=False)\n",
        "\n",
        "\n",
        "dataloaders = {}\n",
        "dataloaders['train'] = train_loader\n",
        "dataloaders['val'] = test_loader\n",
        "\n",
        "dataset_sizes = {x: len(dataloaders[x].dataset) for x in ['train', 'val']}\n",
        "\n",
        "\n",
        "# # Define what device we are using\n",
        "# print(\"CUDA Available: \",torch.cuda.is_available())\n",
        "\n",
        "num_classes = 10\n",
        "\n"
      ],
      "metadata": {
        "id": "OmpAJTEQYCxK"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hUenQbNUXcuN"
      },
      "source": [
        "## Training the model\n",
        "\n",
        "Now, let's write a general function to train a model. Here, we will\n",
        "illustrate:\n",
        "\n",
        "-  Scheduling the learning rate\n",
        "-  Saving the best model\n",
        "\n",
        "In the following, parameter ``scheduler`` is an LR scheduler object from\n",
        "``torch.optim.lr_scheduler``.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QLB81LzNXcuN"
      },
      "outputs": [],
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "                # breakpoint()\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase]\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # deep copy the model\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_model(model):\n",
        "    phase = 'val'\n",
        "    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    running_corrects = 0\n",
        "\n",
        "    # Iterate over data.\n",
        "    for inputs, labels in dataloaders[phase]:\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "\n",
        "        with torch.set_grad_enabled(phase == 'train'):\n",
        "          running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "    epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
        "\n",
        "\n",
        "    print(f'val Acc: {epoch_acc:4f}')\n"
      ],
      "metadata": {
        "id": "lxiD2rD_PVnb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oJjsOglZXcuO"
      },
      "source": [
        "# Train models\n",
        "\n",
        "It should take around 15-25 min on CPU. On GPU though, it takes less than a\n",
        "minute.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "TR6Q82hpXcuO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fc266d0-d5c8-43da-9aef-2f4501480c2d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.6867 Acc: 0.4791\n",
            "val Loss: 0.5391 Acc: 0.8380\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.4138 Acc: 0.8749\n",
            "val Loss: 0.3212 Acc: 0.9014\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2945 Acc: 0.9104\n",
            "val Loss: 0.2367 Acc: 0.9278\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2238 Acc: 0.9332\n",
            "val Loss: 0.1899 Acc: 0.9430\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1809 Acc: 0.9457\n",
            "val Loss: 0.1535 Acc: 0.9553\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1517 Acc: 0.9545\n",
            "val Loss: 0.1239 Acc: 0.9614\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1318 Acc: 0.9604\n",
            "val Loss: 0.1056 Acc: 0.9666\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1146 Acc: 0.9663\n",
            "val Loss: 0.1009 Acc: 0.9683\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1129 Acc: 0.9672\n",
            "val Loss: 0.0993 Acc: 0.9690\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1117 Acc: 0.9671\n",
            "val Loss: 0.0985 Acc: 0.9685\n",
            "\n",
            "Training complete in 1m 15s\n",
            "Best val Acc: 0.969000\n",
            "Net2\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.3374 Acc: 0.6376\n",
            "val Loss: 0.4149 Acc: 0.8802\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.3467 Acc: 0.8992\n",
            "val Loss: 0.2724 Acc: 0.9173\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.2529 Acc: 0.9253\n",
            "val Loss: 0.2128 Acc: 0.9389\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.2024 Acc: 0.9392\n",
            "val Loss: 0.1687 Acc: 0.9511\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.1682 Acc: 0.9501\n",
            "val Loss: 0.1413 Acc: 0.9592\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.1458 Acc: 0.9570\n",
            "val Loss: 0.1230 Acc: 0.9641\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1293 Acc: 0.9615\n",
            "val Loss: 0.1078 Acc: 0.9688\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1165 Acc: 0.9656\n",
            "val Loss: 0.1042 Acc: 0.9697\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1149 Acc: 0.9662\n",
            "val Loss: 0.1025 Acc: 0.9692\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1137 Acc: 0.9661\n",
            "val Loss: 0.1012 Acc: 0.9701\n",
            "\n",
            "Training complete in 1m 8s\n",
            "Best val Acc: 0.970100\n",
            "Net3\n",
            "Epoch 0/9\n",
            "----------\n",
            "train Loss: 1.8932 Acc: 0.5249\n",
            "val Loss: 1.0744 Acc: 0.7724\n",
            "\n",
            "Epoch 1/9\n",
            "----------\n",
            "train Loss: 0.7167 Acc: 0.8350\n",
            "val Loss: 0.4989 Acc: 0.8825\n",
            "\n",
            "Epoch 2/9\n",
            "----------\n",
            "train Loss: 0.4297 Acc: 0.8908\n",
            "val Loss: 0.3515 Acc: 0.9083\n",
            "\n",
            "Epoch 3/9\n",
            "----------\n",
            "train Loss: 0.3254 Acc: 0.9134\n",
            "val Loss: 0.2780 Acc: 0.9261\n",
            "\n",
            "Epoch 4/9\n",
            "----------\n",
            "train Loss: 0.2658 Acc: 0.9286\n",
            "val Loss: 0.2304 Acc: 0.9369\n",
            "\n",
            "Epoch 5/9\n",
            "----------\n",
            "train Loss: 0.2254 Acc: 0.9389\n",
            "val Loss: 0.1977 Acc: 0.9446\n",
            "\n",
            "Epoch 6/9\n",
            "----------\n",
            "train Loss: 0.1963 Acc: 0.9464\n",
            "val Loss: 0.1733 Acc: 0.9525\n",
            "\n",
            "Epoch 7/9\n",
            "----------\n",
            "train Loss: 0.1823 Acc: 0.9503\n",
            "val Loss: 0.1710 Acc: 0.9526\n",
            "\n",
            "Epoch 8/9\n",
            "----------\n",
            "train Loss: 0.1802 Acc: 0.9508\n",
            "val Loss: 0.1690 Acc: 0.9530\n",
            "\n",
            "Epoch 9/9\n",
            "----------\n",
            "train Loss: 0.1781 Acc: 0.9514\n",
            "val Loss: 0.1670 Acc: 0.9538\n",
            "\n",
            "Training complete in 1m 7s\n",
            "Best val Acc: 0.953800\n"
          ]
        }
      ],
      "source": [
        "if train_models: # models should be trained\n",
        "\n",
        "  criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "  for model in models:\n",
        "\n",
        "    # Observe that all parameters are being optimized\n",
        "    optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n",
        "    # Decay LR by a factor of 0.1 every 7 epochs\n",
        "    exp_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)  \n",
        "\n",
        "    # print(\n",
        "    print(model.__class__.__name__)\n",
        "    model = train_model(model, criterion, optimizer, exp_lr_scheduler,\n",
        "                        num_epochs=epochs)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Extract logits"
      ],
      "metadata": {
        "id": "YZd9dvmxZDo-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# extract features over training data \n",
        "def extract_features(model, num_datapoints=100, case='normalized'):\n",
        "    X_train, X_val = torch.empty(1,num_classes, dtype=torch.float16), torch.empty(1,num_classes,dtype=torch.float16)\n",
        "    model.eval()   # Set model to evaluate mode\n",
        "\n",
        "    with torch.no_grad():\n",
        "      for phase in ['train', 'val']:\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                outputs = model(inputs).cpu() # logits which should be saved\n",
        "                # breakpoint()\n",
        "                if case == 'normalized':\n",
        "                    outputs = outputs/outputs.sum(axis=1)[:,None]\n",
        "\n",
        "                \n",
        "                # print(outputs.shape)\n",
        "                # _, preds = torch.max(outputs, 1)\n",
        "                \n",
        "                if phase == 'train':\n",
        "                  X_train = torch.vstack((X_train,outputs))\n",
        "                  if X_train.shape[0] > num_datapoints: break\n",
        "                else:\n",
        "                  X_val = torch.vstack((X_val,outputs))\n",
        "                  if X_val.shape[0] > num_datapoints: break                  \n",
        "\n",
        "    return X_train[1:num_datapoints], X_val[1:num_datapoints]\n"
      ],
      "metadata": {
        "id": "sJEitS1ma2DF"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X, X_val = torch.empty(1,num_classes, dtype=torch.float16), torch.empty(1,num_classes,dtype=torch.float16)\n",
        "y, y_val = [], []\n",
        "\n",
        "num_datapoints = 3000\n",
        "case = 'normalized'\n",
        "\n",
        "for idx, model in enumerate(models):\n",
        "  print(model.__class__.__name__)\n",
        "  train_ft, val_ft = extract_features(model, num_datapoints, case)  \n",
        "  X = torch.vstack((X,train_ft))\n",
        "  X_val = torch.vstack((X_val,val_ft))\n",
        "\n",
        "  y.extend([idx]*train_ft.shape[0]) \n",
        "  y_val.extend([idx]*val_ft.shape[0]) \n",
        "\n",
        "\n",
        "X = X[1:]\n",
        "X_val = X_val[1:]\n",
        "\n",
        "y = torch.tensor(y)\n",
        "y_val = torch.tensor(y_val)\n",
        "\n",
        "idx_t = torch.randperm(X.shape[0])\n",
        "X = X[idx_t]\n",
        "y = y[idx_t]\n",
        "\n",
        "idx_v = torch.randperm(X_val.shape[0])\n",
        "X_val = X_val[idx_v]\n",
        "y_val = y_val[idx_v]\n",
        "\n",
        "\n",
        "print(X.shape, X_val.shape) #, train_ft2.shape, val_ft2.shape)\n",
        "print(y.shape, y_val.shape) #, train_ft2.shape, val_ft2.shape)"
      ],
      "metadata": {
        "id": "QdwFzEMtcb_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8c7970c8-98f0-4e9e-bece-78aadb39eda7"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net\n",
            "Net2\n",
            "Net3\n",
            "torch.Size([8997, 10]) torch.Size([8997, 10])\n",
            "torch.Size([8997]) torch.Size([8997])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train a classifier on logits "
      ],
      "metadata": {
        "id": "nR7EOx31idU-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# multi class\n",
        "#Importing the necessary packages and libaries\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import svm\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ],
      "metadata": {
        "id": "O-q0wEiDVE1Y"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "num_trains = [10, 100, 500, 1000, 2000]\n",
        "\n",
        "for num_train in num_trains:\n",
        "  model_svm = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X[:num_train], y[:num_train])\n",
        "  model_rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X[:num_train], y[:num_train])\n",
        "  # model = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X, y)\n",
        "  # model = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X, y)\n",
        "\n",
        "  # print()\n",
        "  for m in [model_svm, model_rbf]:\n",
        "    pred = m.predict(X_val)\n",
        "    accuracy = m.score(X_val, y_val)\n",
        "    print(f'{num_train}: {accuracy}')\n",
        "    \n",
        "    # cm = confusion_matrix(y_val, pred)\n",
        "\n",
        "    # print(cm)\n",
        "\n",
        "    # plt.imshow(cm)\n",
        "    # plt.show()"
      ],
      "metadata": {
        "id": "fDFhVDRSYDxF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63050b6f-7bb5-4210-a5c9-6e48309d55dd"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10: 0.4706013115482939\n",
            "10: 0.3653440035567411\n",
            "100: 0.5368456152050683\n",
            "100: 0.48860731354896075\n",
            "500: 0.5063910192286317\n",
            "500: 0.6003112148493942\n",
            "1000: 0.5139490941424919\n",
            "1000: 0.582972101811715\n",
            "2000: 0.5013893520062243\n",
            "2000: 0.6501055907524731\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model_svm = svm.SVC(kernel='linear', C=1, decision_function_shape='ovo').fit(X, y)\n",
        "model_rbf = svm.SVC(kernel='rbf', gamma=1, C=1, decision_function_shape='ovo').fit(X, y)\n",
        "# model = svm.SVC(kernel='poly', degree=3, C=1, decision_function_shape='ovo').fit(X, y)\n",
        "# model = svm.SVC(kernel='sigmoid', C=1, decision_function_shape='ovo').fit(X, y)\n",
        "\n",
        "# print()\n",
        "for m in [model_svm, model_rbf]:\n",
        "  pred = m.predict(X_val)\n",
        "  accuracy = m.score(X_val, y_val)\n",
        "  print(f'{X.shape[0]}: {accuracy}')\n",
        "  \n",
        "  cm = confusion_matrix(y_val, pred)\n",
        "\n",
        "  # print(cm)\n",
        "\n",
        "  plt.imshow(cm)\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "5GAS5gT7Qhgx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "DjKyn5PkdGy0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.13"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}